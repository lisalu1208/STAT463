knitr::opts_chunk$set(echo = TRUE)
#Generate a ficticious dataset
M<-rnorm(500)
F<-rnorm(500)
s<-sort(rep(0:1,250))
y<-0.5*M+0.5*F + 4*s + rnorm(500,0,sd=0.4)
data=data.frame(y=y,M=M,F=F,S=s)
data$S<-as.factor(data$S)
mod<-lm(y~M+F+S,data=data)
summary(mod)
confint(mod)
#Step One: create the predictor matrix.
X= cbind(1,data$M,data$F,data$S)
#Step Two: Estimate beta, (X'X)^{-1}X'y
XTX=crossprod(X)
XTXinv=solve(XTX)
XTy=crossprod(X,y)
betahat = XTXinv%*%XTy;betahat
#We have a problem, R read the factor as a vector of ones and twos, when we wanted it to be a vector of zero and ones.
#HENCE, IF YOU TURNED THE CATEGORICAL VARIABLE (such as Sex) INTO a FACTOR IN THE DATASET ITSELF
#you can check if you did this by going
class(data$S)
#subtract one from the column of the factor variable after the cbind operation.
#In this example, the fourth column is the factor variable
#then results will match.
X= cbind(1,data$M,data$F,data$S)
X[,4]<-X[,4]-1
#IF YOU DID NOT CHANGE THE CLASS OF THE CATEGORICAL VARIABLE TO  FACTOR IN THE DATASET, YOU COULD IGNORE THIS.
#Step Two: Estimate beta, (X'X)^{-1}X'y
XTX=crossprod(X)
XTXinv=solve(XTX)
XTy=crossprod(X,y)
betahat = XTXinv%*%XTy;betahat
#The confidence interval  is
#estimate +- Multipler X std error
#We have four estimates, betahat[1], [2], [3], [4].
#We need the 95=100(1-0.05) % multipler if you want a 95 % confidence interval.
n=dim(X)[1]
p<-dim(X)[2]
Mult<-qt(1-0.05/2,df=n-p)
#vbeta = sigma^2_hat XTXinv
#To calculate sigma^2_hat
sigma2hat= sum((y-X%*%betahat)^2)/(n-p)
vbeta= sigma2hat*XTXinv
Stderror = sqrt(diag(vbeta))
#CI for the first coefficient
betahat[1]+c(-1,1)*Mult*Stderror[1]
confint(mod,level =0.95) #check that result matches.
knitr::opts_chunk$set(echo = TRUE)
# Read in the data
dataset <- read.csv("USJudgeRatings.csv")
# Standardise the ratings
library(dplyr)
dataset_std <- dataset %>% mutate(across(where(is.numeric),scale))
summary(dataset_std)
sapply(dataset[,-1], var)
pca <- prcomp(dataset_std[,-1])
screeplot(pca)
biplot(pca)
summary(pca)
factor3 <- factanal(dataset_std[,-1], factors = 3, rotation = "none", control=list(nstart=100));factor3
factor4 <- factanal(dataset_std[,-1], factors = 4, rotation = "none");factor4
factanal(dataset_std[,-1], factors = 3, rotation = "varimax", control=list(nstart=100))
# Standardise the ratings
library(dplyr , quietly = T)
# Perform Pricipal Component Analysis on the standardised dataset
pca <- prcomp(dataset_std[,-1])
# Use the scree plot
screeplot(pca)
pca$sdev
variance_explained <- pca$sdev^2 / sum(pca$sdev^2) * 100
variance_explained
View(variance_explained)
summary(variance_explained)
# Get the percentage of variance explained by each component
variance_explained <- pca$sdev^2 / sum(pca$sdev^2) * 100
variance_explained
summary(pca)
# Get the percentage of variance explained by each component
summary(pca$sdev)
# Get the percentage of variance explained by each component
summary(pca)
pca$x
head(pca)
pca$loadings[,1:2]
pca$rotation
pca$rotation[,1:4]
pca$rotation[,1]
pca$rotation[,1:1]
pca$rotation[1]
pca$rotation[,1]
summary(dataset_std)
pca$rotation[, 2]
pca$rotation[2, ]
pca$rotation[, 2]
pca$rotation[, 1:2]
pca$rotation[1:2, ]
pca$rotation[, 1:2]
